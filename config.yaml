data:
  data_name: 'mnist'
  n_samples: 20000
  n_samples_graph: 5000
  latent_dim: 50

training:
  encoder_decoder:
    num_epochs: 100
    n_batch: 20
    learning_rate: 0.0005
    log_interval: 10
  diffusion:
    num_epochs: 2000
    batch_size: 5000
    learning_rate: 0.00025
    weight_decay: 0.0
    timesteps: 1000
    beta_bounds: [0.0001, 0.02]
    log_interval: 100

models:
  encoder-decoder:
    head: CNN
    model_config: {}
  diffusion:
    time_embed_dim: 100
    hidden_units: 600
    depth: 5
    dropout: 0.1
    use_residual: true
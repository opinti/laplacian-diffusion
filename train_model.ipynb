{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import yaml\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "from data.datasets import get_data, flatten_dataset\n",
    "from models.diffusion import *\n",
    "from models.latent import *\n",
    "from utils import *\n",
    "from tensor_utils import *\n",
    "\n",
    "from specmf.models import Graph\n",
    "\n",
    "torch.set_default_dtype(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('mps')\n",
    "print(\"MPS Built:\", torch.backends.mps.is_built())\n",
    "print(\"MPS Available:\", torch.backends.mps.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load config and initialize vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"config.yaml\", \"r\") as file:\n",
    "    config = yaml.safe_load(file)\n",
    "\n",
    "# Data configuration\n",
    "data_config = config[\"data\"]\n",
    "data_name = data_config[\"data_name\"]\n",
    "n_samples = data_config[\"n_samples\"]\n",
    "n_samples_graph = data_config[\"n_samples_graph\"]\n",
    "latent_dim = data_config[\"latent_dim\"]\n",
    "\n",
    "# Encoder-decoder model\n",
    "encdec_model_config = config[\"models\"][\"encoder-decoder\"]\n",
    "encdec_head = encdec_model_config[\"head\"]\n",
    "encdec_config = encdec_model_config[\"model_config\"]\n",
    "\n",
    "# Encoder-decoder training\n",
    "encdec_training_config = config[\"training\"][\"encoder_decoder\"]\n",
    "encdec_num_epochs = encdec_training_config[\"num_epochs\"]\n",
    "encdec_n_batch = encdec_training_config[\"n_batch\"]\n",
    "encdec_learning_rate = encdec_training_config[\"learning_rate\"]\n",
    "encdec_log_interval = encdec_training_config[\"log_interval\"]\n",
    "\n",
    "# Diffusion model\n",
    "diffusion_model_config = config[\"models\"][\"diffusion\"]\n",
    "time_embed_dim = diffusion_model_config[\"time_embed_dim\"]\n",
    "diffusion_hidden_units = diffusion_model_config[\"hidden_units\"]\n",
    "diffusion_depth = diffusion_model_config[\"depth\"]\n",
    "diffusion_dropout = diffusion_model_config[\"dropout\"]\n",
    "diffusion_use_residual = diffusion_model_config[\"use_residual\"]\n",
    "\n",
    "# Diffusion training\n",
    "diffusion_training_config = config[\"training\"][\"diffusion\"]\n",
    "diffusion_num_epochs = diffusion_training_config[\"num_epochs\"]\n",
    "diffusion_batch_size = diffusion_training_config[\"batch_size\"]\n",
    "diffusion_learning_rate = diffusion_training_config[\"learning_rate\"]\n",
    "diffusion_weight_decay = diffusion_training_config[\"weight_decay\"]\n",
    "timesteps = diffusion_training_config[\"timesteps\"]\n",
    "beta_bounds = tuple(diffusion_training_config[\"beta_bounds\"])\n",
    "diffusion_log_interval = diffusion_training_config[\"log_interval\"]\n",
    "\n",
    "print(yaml.dump(config))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data and create graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "X = get_data(\n",
    "    data_name=data_name,\n",
    "    n_samples=n_samples,\n",
    ").to(device)\n",
    "\n",
    "X, shape_X = flatten_dataset(X, return_shape=True)  # Shape: (n_samples, dim1 * dim2)\n",
    "\n",
    "_, dim1, dim2 = shape_X\n",
    "\n",
    "X_g = X[:n_samples_graph].to(device)\n",
    "\n",
    "print(f\"{X.shape=}\")\n",
    "print(f\"{X_g.shape=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the graph\n",
    "graph_config = {\n",
    "    'metric': 'euclidean',\n",
    "    'dist_space': 'ambient',\n",
    "    'method': 'full',\n",
    "    'corr_scale': None,\n",
    "    'k_adj': 7,\n",
    "    'p': 0.5,\n",
    "    'q': 0.5,\n",
    "}\n",
    "\n",
    "graph = Graph(\n",
    "    data=X_g.detach().cpu().numpy(),\n",
    "    **graph_config,\n",
    ")\n",
    "\n",
    "# Compute graph laplacian and eigenvectors\n",
    "L = graph.graph_laplacian\n",
    "_, eigvecs = graph.laplacian_eig()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Latent space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the embedding z\n",
    "Z_g = torch.tensor(eigvecs[:, :latent_dim]).float().to(device)\n",
    "\n",
    "# Compute linear encoder and decoder\n",
    "decoder_matrix = X_g.T @ Z_g\n",
    "linear_decoder = LinearEmbedding(decoder_matrix)\n",
    "\n",
    "encoder_matrix = compute_linear_transformation(\n",
    "    X_g.T.detach().cpu(),\n",
    "    Z_g.T.detach().cpu(),\n",
    ").to(device)\n",
    "linear_encoder = LinearEmbedding(encoder_matrix)\n",
    "\n",
    "Z_l = linear_encoder(X).to(device)\n",
    "print(X.shape, Z_l.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "U = decoder_matrix.detach().cpu().numpy()\n",
    "fig, axs = plt.subplots(3, 6, figsize=(24, 12))\n",
    "plt.subplots_adjust(hspace=0.3, wspace=0.3)\n",
    "\n",
    "i = 0\n",
    "for r in range(3):\n",
    "    for c in range(6):\n",
    "        axs[r, c].imshow(U[:, i].reshape(dim1, dim2), cmap='gray')\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inds_centroids, labels = graph.cluster(n=10)\n",
    "\n",
    "_Z_g = Z_g.detach().cpu().numpy()\n",
    "_Z_l = Z_l.detach().cpu().numpy()\n",
    "\n",
    "fig, axs = plt.subplots(2, 4, figsize=(14, 7))\n",
    "plt.subplots_adjust(hspace=0.3, wspace=0.3)\n",
    "\n",
    "for i in range(8):\n",
    "    r, c = i//4, i%4\n",
    "    x, y = _Z_g[:, i], _Z_g[:, i+1]\n",
    "    axs[r, c].scatter(x, y, s=5, c=labels, cmap='viridis')\n",
    "    axs[r, c].grid('on')\n",
    "    axs[r, c].set_xlabel(fr\"$\\phi_{i+1}$\")\n",
    "    axs[r, c].set_ylabel(fr\"$\\phi_{i+2}$\")\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(2, 4, figsize=(14, 7))\n",
    "plt.subplots_adjust(hspace=0.3, wspace=0.3)\n",
    "\n",
    "for i in range(8):\n",
    "    r, c = i//4, i%4\n",
    "    x, y = _Z_l[:, i], _Z_l[:, i+1]\n",
    "    axs[r, c].scatter(x, y, s=2.5)\n",
    "    x, y = _Z_g[:, i], _Z_g[:, i+1]\n",
    "    axs[r, c].scatter(x, y, s=5, c=labels, cmap='viridis')\n",
    "    axs[r, c].grid('on')\n",
    "    axs[r, c].set_xlabel(fr\"$\\phi_{i+1}$\")\n",
    "    axs[r, c].set_ylabel(fr\"$\\phi_{i+2}$\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_ind = np.random.randint(0, X_g.shape[0])\n",
    "\n",
    "x_true = X_g[sample_ind, :].reshape(1, -1)\n",
    "z_true = Z_g[sample_ind, :].reshape(1, -1)\n",
    "\n",
    "x_decoded = linear_decoder(z_true)\n",
    "x_encoded = linear_encoder(x_true)\n",
    "x_encoded_decoded = linear_decoder(x_encoded)\n",
    "\n",
    "x_true = x_true.detach().cpu()\n",
    "z_true = z_true.detach().cpu()\n",
    "x_decoded = x_decoded.detach().cpu()\n",
    "x_encoded = x_encoded.detach().cpu()\n",
    "x_encoded_decoded = x_encoded_decoded.detach().cpu()\n",
    "\n",
    "vmin = min(x_true.min(), x_decoded.min(), x_encoded_decoded.min())\n",
    "vmax = max(x_true.max(), x_decoded.max(), x_encoded_decoded.max())\n",
    "print(vmin, vmax)\n",
    "\n",
    "# Errors\n",
    "error_decoder = torch.norm(x_true - x_decoded).item() / torch.norm(x_true).item()\n",
    "error_encoder = torch.norm(z_true - x_encoded).item() / torch.norm(z_true).item()\n",
    "error_encoded_decoded = torch.norm(x_true - x_encoded_decoded).item() / torch.norm(x_true).item()\n",
    "\n",
    "print(f\"Error decoder: {error_decoder}\")\n",
    "print(f\"Error encoder: {error_encoder}\")\n",
    "print(f\"Error encoded-decoded: {error_encoded_decoded}\")\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1, 3)\n",
    "ax[0].imshow(x_true.reshape(dim1, dim2), cmap='gray', vmin=vmin, vmax=vmax)\n",
    "ax[0].set_title('True image')\n",
    "ax[1].imshow(x_decoded.reshape(dim1, dim2), cmap='gray', vmin=vmin, vmax=vmax)\n",
    "ax[1].set_title('Decoded image')\n",
    "ax[2].imshow(x_encoded_decoded.reshape(dim1, dim2), cmap='gray', vmin=vmin, vmax=vmax)\n",
    "ax[2].set_title('Encoded-decoded image')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_ind = np.random.randint(0, X.shape[0])\n",
    "\n",
    "x_true = X[sample_ind, :].reshape(1, -1)\n",
    "z_l = Z_l[sample_ind, :].reshape(1, -1)\n",
    "\n",
    "x_decoded = linear_decoder(z_l)\n",
    "\n",
    "x_true = x_true.detach().cpu()\n",
    "z_l = z_l.detach().cpu()\n",
    "x_decoded = x_decoded.detach().cpu()\n",
    "\n",
    "vmin = min(x_true.min(), x_decoded.min())\n",
    "vmax = max(x_true.max(), x_decoded.max())\n",
    "\n",
    "fig, ax = plt.subplots(1, 2)\n",
    "ax[0].imshow(x_true.reshape(dim1, dim2), cmap='gray', vmin=vmin, vmax=vmax)\n",
    "ax[0].set_title('True image')\n",
    "ax[1].imshow(x_decoded.reshape(dim1, dim2), cmap='gray', vmin=vmin, vmax=vmax)\n",
    "ax[1].set_title('Decoded image')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train encoder and decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "supervised_dataloader = DataLoader(\n",
    "    TensorDataset(X_g, Z_g),\n",
    "    batch_size=n_samples_graph // encdec_n_batch,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "unsupervised_dataloader = DataLoader(\n",
    "    TensorDataset(X),\n",
    "    batch_size=n_samples // encdec_n_batch,\n",
    "    shuffle=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if encdec_head == \"CNN\":\n",
    "    head_enc = CNNHead(num_features=encdec_n_features)\n",
    "    head_dec = CNNHead(num_features=encdec_n_features)\n",
    "elif encdec_head == \"UNet\":\n",
    "    head_enc = UNetHead(num_features=encdec_n_features)\n",
    "    head_dec = UNetHead(num_features=encdec_n_features)\n",
    "\n",
    "# Encoder\n",
    "encoder = LatentEmbedding(\n",
    "    data_shape=(1, 1, latent_dim,),\n",
    "    backbone=linear_encoder,\n",
    "    head=head_enc,\n",
    ").to(device)\n",
    "\n",
    "print(\"Encoder parameters count:\")\n",
    "count_parameters(encoder)\n",
    "\n",
    "# Decoder\n",
    "decoder = LatentEmbedding(\n",
    "    data_shape=(1, dim1, dim2,),\n",
    "    backbone=linear_decoder,\n",
    "    head=head_dec,\n",
    ").to(device)\n",
    "\n",
    "print(\"\\nDecoder parameters count:\")\n",
    "count_parameters(decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder_optimizer = optim.Adam(\n",
    "    list(encoder.parameters()) + list(decoder.parameters()),\n",
    "    lr=encdec_learning_rate,\n",
    ")\n",
    "\n",
    "for epoch in range(encdec_num_epochs):\n",
    "\n",
    "    encoder.train()\n",
    "    decoder.train()\n",
    "\n",
    "    loss_supervised = 0.0\n",
    "    loss_unsupervised = 0.0\n",
    "    batch_count = 0\n",
    "    \n",
    "    for batch_s, batch_us in zip(supervised_dataloader, unsupervised_dataloader):\n",
    "        x_g, z_g = batch_s\n",
    "        x = batch_us[0]\n",
    "\n",
    "        autoencoder_optimizer.zero_grad()\n",
    "\n",
    "        z_hat = encoder(x_g)\n",
    "        loss_latent = F.mse_loss(z_hat, z_g)\n",
    "        loss_latent.backward()\n",
    "        loss_supervised += loss_latent.item()\n",
    "\n",
    "        z_hat = encoder(x)\n",
    "        x_hat = decoder(z_hat)\n",
    "        loss_recon = F.mse_loss(x_hat, x)\n",
    "        loss_recon.backward()\n",
    "        loss_unsupervised += loss_recon.item()\n",
    "\n",
    "        autoencoder_optimizer.step()\n",
    "        batch_count += 1\n",
    "\n",
    "    loss_supervised /= batch_count\n",
    "    loss_unsupervised /= batch_count\n",
    "\n",
    "    if (epoch + 1) % encdec_log_interval == 0:\n",
    "        print(f\"Epoch {epoch+1} : \"\n",
    "                f\"Supervised Loss: {loss_supervised:.5f}, \"\n",
    "                f\"Unsupervised Loss: {loss_unsupervised:.5f}\")\n",
    "\n",
    "    encoder.eval()\n",
    "    decoder.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute latent representation for the whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    Z = encoder(X)\n",
    "    X_hat = decoder(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inds_centroids, labels = graph.cluster(n=10)\n",
    "\n",
    "_Z_g = Z_g.detach().cpu().numpy()\n",
    "_Z = Z.detach().cpu().numpy()\n",
    "\n",
    "fig, axs = plt.subplots(2, 4, figsize=(14, 7))\n",
    "plt.subplots_adjust(hspace=0.3, wspace=0.3)\n",
    "\n",
    "for i in range(8):\n",
    "    r, c = i//4, i%4\n",
    "    x, y = _Z_g[:, i], _Z_g[:, i+1]\n",
    "    axs[r, c].scatter(x, y, s=5, c=labels, cmap='viridis')\n",
    "    axs[r, c].grid('on')\n",
    "    axs[r, c].set_xlabel(fr\"$\\phi_{i+1}$\")\n",
    "    axs[r, c].set_ylabel(fr\"$\\phi_{i+2}$\")\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(2, 4, figsize=(14, 7))\n",
    "plt.subplots_adjust(hspace=0.3, wspace=0.3)\n",
    "\n",
    "for i in range(8):\n",
    "    r, c = i//4, i%4\n",
    "    x, y = _Z[:, i], _Z[:, i+1]\n",
    "    axs[r, c].scatter(x, y, s=2.5)\n",
    "    # x, y = _Z_g[:, i], _Z_g[:, i+1]\n",
    "    # axs[r, c].scatter(x, y, s=5, c=labels, cmap='viridis')\n",
    "    axs[r, c].grid('on')\n",
    "    axs[r, c].set_xlabel(fr\"$\\phi_{i+1}$\")\n",
    "    axs[r, c].set_ylabel(fr\"$\\phi_{i+2}$\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(5):\n",
    "    sample_ind = np.random.randint(0, X.shape[0])\n",
    "\n",
    "    x_true = X[sample_ind, :].reshape(1, -1).cpu().numpy()\n",
    "    x_hat = X_hat[sample_ind, :].detach().cpu().numpy().reshape(1, -1)\n",
    "\n",
    "    vmin = min(x_true.min(), x_hat.min())\n",
    "    vmax = max(x_true.max(), x_hat.max())\n",
    "\n",
    "    fig, ax = plt.subplots(1, 2)\n",
    "    ax[0].imshow(x_true.reshape(dim1, dim2), cmap='gray', vmin=vmin, vmax=vmax)\n",
    "    ax[0].set_title('True image')\n",
    "    ax[1].imshow(x_hat.reshape(dim1, dim2), cmap='gray', vmin=vmin, vmax=vmax)\n",
    "    ax[1].set_title('Encoded-decoded image')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build model and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z_n, Z_mean, Z_std = normalize_tensor(Z)\n",
    "\n",
    "dataloader = DataLoader(\n",
    "    TensorDataset(Z_n),\n",
    "    batch_size=diffusion_batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "sample = next(iter(dataloader))[0]\n",
    "in_dim = sample.shape[1]\n",
    "\n",
    "diffusion = DiffusionProcess(\n",
    "    timesteps=timesteps, beta_bounds=beta_bounds, device=device\n",
    ")\n",
    "\n",
    "model = LatentDiffusionModel(\n",
    "    input_dim=in_dim,\n",
    "    time_embed_dim=time_embed_dim,\n",
    "    hidden_units=diffusion_hidden_units,\n",
    "    dropout=diffusion_dropout,\n",
    "    depth=diffusion_depth,\n",
    "    use_residual=diffusion_use_residual,\n",
    "    mean=Z_mean,\n",
    "    std=Z_std,\n",
    "    decoder=decoder,\n",
    ").to(device)\n",
    "\n",
    "count_parameters(model)\n",
    "\n",
    "optimizer = optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=diffusion_learning_rate,\n",
    "    weight_decay=diffusion_weight_decay,\n",
    ")\n",
    "\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "loss_history = []\n",
    "\n",
    "for epoch in range(diffusion_num_epochs):\n",
    "    model.train()\n",
    "    loss_epoch = 0\n",
    "\n",
    "    for z, in dataloader:\n",
    "\n",
    "        t = torch.randint(0, timesteps, (z.size(0),)).to(device)\n",
    "        t_normalized = t / (timesteps - 1)\n",
    "\n",
    "        # Denoising loss\n",
    "        z_noisy, noise = diffusion.forward(z, t)\n",
    "        predicted_noise = model(z_noisy, t_normalized)\n",
    "        loss = criterion(predicted_noise, noise)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_epoch += loss.item()\n",
    "\n",
    "    loss_epoch /= len(dataloader)\n",
    "    loss_history.append(loss_epoch)\n",
    "    if (epoch + 1) % diffusion_log_interval == 0:\n",
    "        print(f\"Epoch {epoch + 1}, Loss: {loss_epoch}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot loss\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 6))\n",
    "ax.plot(loss_history)\n",
    "ax.set_title(\"Training Loss\")\n",
    "ax.set_xlabel(\"Epoch\")\n",
    "ax.set_ylabel(\"MSE Loss\")\n",
    "ax.set_yscale(\"log\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = generate_funny_name()\n",
    "print(f\"Experiment name: {experiment_name}\")\n",
    "\n",
    "save_experiment(model, optimizer, loss_history, config, experiment_name)\n",
    "update_experiment_log(experiment_name, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate gaussian noise and denoise it to latent space embeddings z \n",
    "x_samples = diffusion.reverse(\n",
    "    model,\n",
    "    num_samples=25,\n",
    "    in_dim=latent_dim,\n",
    "    device=device,\n",
    "    denormalize=True,\n",
    "    decode=True,\n",
    ").detach().cpu().numpy()\n",
    "\n",
    "n_rows, n_cols = 5, 5\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(12, 10))\n",
    "\n",
    "for i in range(n_rows * n_cols):\n",
    "    ax = axes[i // n_cols, i % n_cols]\n",
    "    sample = x_samples[i].reshape(dim1, dim2)\n",
    "    sample_plot = ax.imshow(sample, cmap=\"gray\")\n",
    "    ax.axis(\"off\")\n",
    "    fig.colorbar(sample_plot)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"saved_models/{experiment_name}/samples.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-mps",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
